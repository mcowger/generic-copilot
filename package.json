{
	"name": "generic-copilot-providers",
	"publisher": "mcowger",
	"displayName": "OAI Compatible Provider for Copilot",
	"description": "An extension that integrates Openai Compatible Inference Providers into GitHub Copilot Chat",
	"icon": "assets/logo.png",
	"keywords": [
        "ai",
        "chat",
        "copilot",
        "github-copilot",
        "language-model"
    ],
	"repository": {
		"type": "git",
		"url": "https://github.com/mcowger/generic-copilot-providers"
	},
	"version": "0.9.0",
	"engines": {
		"vscode": "^1.105.0"
	},
	"extensionDependencies": [
        "github.copilot-chat"
    ],
	"categories": [
		"AI",
		"Chat"
	],
	"license": "MIT",
	"enabledApiProposals": [
        "chatProvider",
		"languageModelCapabilities",
		"languageModelThinkingPart"
    ],
	"contributes": {
		"languageModelChatProviders": [
			{
				"vendor": "oaicopilot",
				"displayName": "OAI Compatible",
				"managementCommand": "oaicopilot.setApikey"
			}
		],
		"commands": [
			{
				"command": "oaicopilot.setApikey",
				"title": "OAICopilot: Set OAI Compatible Apikey"
			},
			{
				"command": "oaicopilot.setProviderApikey",
				"title": "OAICopilot: Set OAI Compatible Multi-Provider Apikey"
			}
		],
		"configuration": {
			"title": "OAI Compatible Copilot",
			"properties": {
				"oaicopilot.baseUrl": {
					"type": "string",
					"default": "https://router.huggingface.co/v1",
					"description": "The base URL for the Openai Compatible Inference API. Default value is Hugging Face."
				},
				"oaicopilot.providers": {
					"type": "array",
					"default": [],
					"items": {
						"type": "object",
						"properties": {
							"key": {
								"type": "string",
								"description": "Canonical provider key (lowercase, used as owned_by and for API key storage)."
							},
							"displayName": {
								"type": "string",
								"description": "(Optional) Display name for the provider."
							},
							"baseUrl": {
								"type": "string",
								"description": "Base URL for the provider's API endpoint."
							},
							"defaults": {
								"type": "object",
								"description": "(Optional) Default parameters that models can inherit.",
								"properties": {
									"context_length": {
										"type": "number",
										"description": "Default context length for models."
									},
									"max_tokens": {
										"type": "number",
										"description": "Default max tokens for models."
									},
									"max_completion_tokens": {
										"type": "number",
										"description": "Default max completion tokens for models."
									},
									"temperature": {
										"type": [
											"number",
											"null"
										],
										"description": "Default temperature for models."
									},
									"top_p": {
										"type": [
											"number",
											"null"
										],
										"description": "Default top_p for models."
									},
									"top_k": {
										"type": "number",
										"description": "Default top_k for models."
									},
									"min_p": {
										"type": "number",
										"description": "Default min_p for models."
									},
									"frequency_penalty": {
										"type": "number",
										"description": "Default frequency penalty for models."
									},
									"presence_penalty": {
										"type": "number",
										"description": "Default presence penalty for models."
									},
									"repetition_penalty": {
										"type": "number",
										"description": "Default repetition penalty for models."
									},
									"vision": {
										"type": "boolean",
										"description": "Default vision capability for models."
									},
									"family": {
										"type": "string",
										"description": "Default model family for models."
									},
									"reasoning_effort": {
										"type": "string",
										"description": "Default reasoning effort for models."
									},
									"enable_thinking": {
										"type": "boolean",
										"description": "Default enable_thinking for models."
									},
									"thinking_budget": {
										"type": "number",
										"description": "Default thinking budget for models."
									},
									"thinking": {
										"type": "object",
										"description": "Default thinking configuration for models."
									},
									"reasoning": {
										"type": "object",
										"description": "Default reasoning configuration for models."
									},
									"extra": {
										"type": "object",
										"description": "Default extra parameters for models."
									}
								}
							}
						},
						"required": [
							"key",
							"baseUrl"
						]
					},
					"description": "A list of provider configurations. Models can reference providers to inherit baseUrl, owned_by, and default parameters."
				},
				"oaicopilot.models": {
					"type": "array",
					"default": [],
					"items": {
						"type": "object",
						"properties": {
							"id": {
								"type": "string",
								"description": "Model ID (e.g., 'glm-4.6')."
							},
							"provider": {
								"type": "string",
								"description": "(Optional) Reference to a provider key. If specified, the model inherits baseUrl, owned_by, and defaults from the provider configuration."
							},
							"configId": {
								"type": "string",
								"description": "(Optional) Configuration ID for this model. Allows defining the same model with different settings (e.g. 'glm-4.6::thinking', 'glm-4.6::no-thinking')."
							},
							"owned_by": {
								"type": "string",
								"description": "Model provider (e.g., 'zai', 'openai'). Can be inherited from provider if 'provider' field is specified."
							},
							"family": {
								"type": "string",
								"description": "Model family (e.g., 'gpt-4', 'claude-3', 'gemini'). Enables model-specific optimizations and behaviors. Defaults to 'oai-compatible' if not specified."
							},
							"baseUrl": {
								"type": "string",
								"description": "Base URL for the model provider. If not provided, the global oaicopilot.baseUrl will be used."
							},
							"context_length": {
								"type": "number",
								"default": 128000,
								"minimum": 1000,
								"maximum": 10000000,
								"description": "Model support context length. Default is 128000."
							},
							"vision": {
								"type": "boolean",
								"default": false,
								"description": "Model support vision. Default is false."
							},
							"max_tokens": {
								"type": "number",
								"default": 4096,
								"minimum": 1,
								"maximum": 10000000,
								"description": "Maximum number of tokens to generate (range: [1, context_length)). Default is 4096."
							},
							"max_completion_tokens": {
								"type": "number",
								"default": 4096,
								"minimum": 1,
								"maximum": 10000000,
								"description": "Maximum number of tokens to generate (OpenAI new standard parameter)."
							},
							"reasoning_effort": {
								"type": "string",
								"default": "medium",
								"enum": [
									"high",
									"medium",
									"low",
									"minimal"
								],
								"description": "Reasoning effort level (OpenAI reasoning configuration)"
							},
							"thinking": {
								"type": "object",
								"description": "Thinking configuration for Zai provider",
								"properties": {
									"type": {
										"type": "string",
										"enum": [
											"enabled",
											"disabled"
										],
										"description": "Set to 'enabled' to enable thinking, 'disabled' to disable thinking"
									}
								}
							},
							"enable_thinking": {
								"type": "boolean",
								"default": false,
								"description": "Switches between thinking and non-thinking modes. Not required."
							},
							"thinking_budget": {
								"type": "number",
								"default": 128,
								"minimum": 128,
								"maximum": 10000000,
								"description": "Maximum number of tokens for chain-of-thought output. Not required."
							},
							"temperature": {
								"type": "number",
								"default": 0,
								"minimum": 0,
								"maximum": 2,
								"description": "Sampling temperature (range: [0, 2]). Lower values make output more deterministic, higher values make it more creative. Default is 0."
							},
							"top_p": {
								"type": "number",
								"default": 1,
								"minimum": 0,
								"maximum": 1,
								"description": "Top-p sampling value (range: (0, 1]). Default is 1."
							},
							"top_k": {
								"type": "number",
								"default": 50,
								"minimum": 1,
								"description": "Top-k sampling value (range: [1, Infinity)). Not required."
							},
							"min_p": {
								"type": "number",
								"default": 0,
								"minimum": 0,
								"maximum": 1,
								"description": "Minimum probability threshold (range: [0, 1]). Not required."
							},
							"frequency_penalty": {
								"type": "number",
								"default": 0,
								"minimum": -2,
								"maximum": 2,
								"description": "Frequency penalty (range: [-2, 2]). Not required."
							},
							"presence_penalty": {
								"type": "number",
								"default": 0,
								"minimum": -2,
								"maximum": 2,
								"description": "Presence penalty (range: [-2, 2]). Not required."
							},
							"repetition_penalty": {
								"type": "number",
								"default": 0,
								"minimum": 0,
								"maximum": 2,
								"description": "Repetition penalty (range: (0, 2]). Not required."
							},
							"reasoning": {
								"type": "object",
								"default": {
									"effort": "medium"
								},
								"properties": {
									"effort": {
										"type": "string",
										"default": "medium",
										"enum": [
											"high",
											"medium",
											"low",
											"minimal",
											"auto"
										],
										"description": "Reasoning effort level for OpenRouter/xAI (high, medium, low, minimal, auto)"
									},
									"exclude": {
										"type": "boolean",
										"default": false,
										"description": "Exclude reasoning tokens from the final response"
									},
									"max_tokens": {
										"type": "number",
										"default": 2000,
										"minimum": 1,
										"description": "Specific token limit for reasoning (Anthropic-style, alternative to effort)"
									},
									"enabled": {
										"type": "boolean",
										"default": true,
										"description": "Enable reasoning (inferred from effort or max_tokens if not specified)"
									}
								},
								"description": "Reasoning configuration for OpenRouter-compatible providers"
							},
							"extra": {
								"type": "object",
								"description": "Extra request parameters that will be used in /chat/completions."
							}
						},
						"required": [
							"id"
						]
					},
					"description": "A list of preferred models to use. If provided, these models will be used directly instead of fetching from the API."
				},
				"oaicopilot.retry": {
					"type": "object",
					"default": {
						"enabled": true,
						"max_attempts": 3,
						"interval_ms": 1000
					},
					"properties": {
						"enabled": {
							"type": "boolean",
							"default": true,
							"description": "Enable retry mechanism for api errors. Default is true."
						},
						"max_attempts": {
							"type": "number",
							"default": 3,
							"minimum": 1,
							"description": "Maximum number of retry attempts. Default is 3."
						},
						"interval_ms": {
							"type": "number",
							"default": 1000,
							"minimum": 1,
							"description": "Interval between retry attempts in milliseconds. Default is 1000 (1 seconds)."
						}
					},
					"description": "Retry configuration for handling api errors like [429, 500, 502, 503, 504]."
				},
				"oaicopilot.delay": {
					"type": "number",
					"default": 0,
					"minimum": 0,
					"description": "Fixed delay in milliseconds between consecutive requests. Default is 0 (no delay)."
				}
			}
		}
	},
	"main": "./out/extension.js",
	"scripts": {
		"vscode:prepublish": "npm run compile",
		"download-api": "npx dts dev && mv vscode.proposed.*.ts src",
		"compile": "tsc -p ./",
		"lint": "eslint",
		"format": "prettier --write .",
		"watch": "tsc -watch -p ./",
		"test": "npm run compile && vscode-test"
	},
	"dependencies": {},
	"devDependencies": {
		"@eslint/js": "^9.13.0",
		"@stylistic/eslint-plugin": "^2.9.0",
		"@types/node": "^22",
		"@types/mocha": "^10.0.6",
		"@vscode/dts": "^0.4.1",
		"@types/vscode": "^1.104.0",
		"@vscode/test-cli": "^0.0.11",
		"@vscode/test-electron": "^2.5.2",
		"eslint": "^9.13.0",
		"prettier": "^3.1.0",
		"typescript": "^5.9.2",
		"typescript-eslint": "^8.39.0"
	}
}
